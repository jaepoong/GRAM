{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a= torch.dot(torch.tensor([2,3]),torch.tensor([2,1]))\n",
    "torch.bmm(torch.FloatTensor(10,3,5),torch.FloatTensor(10,5,3)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data=np.load(\"../data/cats/fid_files/cats_64.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"m\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "# num_step = 4, 배치 = 3, 크기는 = 8*8\n",
    "def normalize_vecs(vectors: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalize vector lengths.\n",
    "    \"\"\"\n",
    "    return vectors / (torch.norm(vectors, dim=-1, keepdim=True))\n",
    "\n",
    "x, y = torch.meshgrid(torch.linspace(-1, 1, 8, ),\n",
    "                          torch.linspace(-1, 1, 8))\n",
    "x=x.T.flatten()\n",
    "y=y.T.flatten()\n",
    "z = -torch.ones_like(x) / np.tan((2 * math.pi * 30 / 360)/2)\n",
    "\n",
    "ray_d_cam= normalize_vecs(torch.stack([x, y, z], -1))\n",
    "z_vals=torch.linspace(2, 6, 4).reshape(1, 4, 1).repeat(64, 1, 1)\n",
    "points = ray_d_cam.unsqueeze(1).repeat(1, 4, 1) * z_vals\n",
    "points = torch.stack(3*[points]) \n",
    "z_vals = torch.stack(3*[z_vals]) \n",
    "ray_d_cam = torch.stack(3*[ray_d_cam]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sampled_points(points, z_vals, ray_directions, h_stddev=1, v_stddev=1, h_mean=math.pi * 0.5, v_mean=math.pi * 0.5, mode='normal'):\n",
    "    \"\"\"Samples a camera position and maps points in camera space to world space.\"\"\"\n",
    "\n",
    "    n, num_rays, num_steps, channels = points.shape\n",
    "\n",
    "    points, z_vals = perturb_points(points, z_vals, ray_directions)\n",
    "\n",
    "\n",
    "    camera_origin, pitch, yaw = sample_camera_positions(n=points.shape[0], r=1, horizontal_stddev=h_stddev, vertical_stddev=v_stddev, horizontal_mean=h_mean, vertical_mean=v_mean, mode=mode)\n",
    "    forward_vector = normalize_vecs(-camera_origin)\n",
    "\n",
    "    cam2world_matrix = create_cam2world_matrix(forward_vector, camera_origin)\n",
    "\n",
    "    points_homogeneous = torch.ones((points.shape[0], points.shape[1], points.shape[2], points.shape[3] + 1))\n",
    "    points_homogeneous[:, :, :, :3] = points\n",
    "\n",
    "    # should be n x 4 x 4 , n x r^2 x num_steps x 4\n",
    "    transformed_points = torch.bmm(cam2world_matrix, points_homogeneous.reshape(n, -1, 4).permute(0,2,1)).permute(0, 2, 1).reshape(n, num_rays, num_steps, 4)\n",
    "\n",
    "\n",
    "    transformed_ray_directions = torch.bmm(cam2world_matrix[..., :3, :3], ray_directions.reshape(n, -1, 3).permute(0,2,1)).permute(0, 2, 1).reshape(n, num_rays, 3)\n",
    "\n",
    "    homogeneous_origins = torch.zeros((n, 4, num_rays))\n",
    "    homogeneous_origins[:, 3, :] = 1\n",
    "    transformed_ray_origins = torch.bmm(cam2world_matrix, homogeneous_origins).permute(0, 2, 1).reshape(n, num_rays, 4)[..., :3]\n",
    "\n",
    "    return transformed_points[..., :3], z_vals, transformed_ray_directions, transformed_ray_origins, pitch, yaw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_points(points, z_vals, ray_directions):\n",
    "    distance_between_points = z_vals[:,:,1:2,:] - z_vals[:,:,0:1,:]\n",
    "    offset = (torch.rand(z_vals.shape)-0.5) * distance_between_points\n",
    "    z_vals = z_vals + offset\n",
    "\n",
    "    points = points + offset * ray_directions.unsqueeze(2)\n",
    "    return points, z_vals\n",
    "\n",
    "perturb_points(points,z_vals,ray_d_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 4, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2506, -0.2506, -0.9351],\n",
       "         [-0.2545, -0.1818, -0.9498],\n",
       "         [-0.2572, -0.1102, -0.9600],\n",
       "         [-0.2586, -0.0369, -0.9653],\n",
       "         [-0.2586,  0.0369, -0.9653],\n",
       "         [-0.2572,  0.1102, -0.9600],\n",
       "         [-0.2545,  0.1818, -0.9498],\n",
       "         [-0.2506,  0.2506, -0.9351]],\n",
       "\n",
       "        [[-0.1818, -0.2545, -0.9498],\n",
       "         [-0.1847, -0.1847, -0.9653],\n",
       "         [-0.1868, -0.1121, -0.9760],\n",
       "         [-0.1878, -0.0376, -0.9815],\n",
       "         [-0.1878,  0.0376, -0.9815],\n",
       "         [-0.1868,  0.1121, -0.9760],\n",
       "         [-0.1847,  0.1847, -0.9653],\n",
       "         [-0.1818,  0.2545, -0.9498]],\n",
       "\n",
       "        [[-0.1102, -0.2572, -0.9600],\n",
       "         [-0.1121, -0.1868, -0.9760],\n",
       "         [-0.1134, -0.1134, -0.9871],\n",
       "         [-0.1140, -0.0380, -0.9928],\n",
       "         [-0.1140,  0.0380, -0.9928],\n",
       "         [-0.1134,  0.1134, -0.9871],\n",
       "         [-0.1121,  0.1868, -0.9760],\n",
       "         [-0.1102,  0.2572, -0.9600]],\n",
       "\n",
       "        [[-0.0369, -0.2586, -0.9653],\n",
       "         [-0.0376, -0.1878, -0.9815],\n",
       "         [-0.0380, -0.1140, -0.9928],\n",
       "         [-0.0382, -0.0382, -0.9985],\n",
       "         [-0.0382,  0.0382, -0.9985],\n",
       "         [-0.0380,  0.1140, -0.9928],\n",
       "         [-0.0376,  0.1878, -0.9815],\n",
       "         [-0.0369,  0.2586, -0.9653]],\n",
       "\n",
       "        [[ 0.0369, -0.2586, -0.9653],\n",
       "         [ 0.0376, -0.1878, -0.9815],\n",
       "         [ 0.0380, -0.1140, -0.9928],\n",
       "         [ 0.0382, -0.0382, -0.9985],\n",
       "         [ 0.0382,  0.0382, -0.9985],\n",
       "         [ 0.0380,  0.1140, -0.9928],\n",
       "         [ 0.0376,  0.1878, -0.9815],\n",
       "         [ 0.0369,  0.2586, -0.9653]],\n",
       "\n",
       "        [[ 0.1102, -0.2572, -0.9600],\n",
       "         [ 0.1121, -0.1868, -0.9760],\n",
       "         [ 0.1134, -0.1134, -0.9871],\n",
       "         [ 0.1140, -0.0380, -0.9928],\n",
       "         [ 0.1140,  0.0380, -0.9928],\n",
       "         [ 0.1134,  0.1134, -0.9871],\n",
       "         [ 0.1121,  0.1868, -0.9760],\n",
       "         [ 0.1102,  0.2572, -0.9600]],\n",
       "\n",
       "        [[ 0.1818, -0.2545, -0.9498],\n",
       "         [ 0.1847, -0.1847, -0.9653],\n",
       "         [ 0.1868, -0.1121, -0.9760],\n",
       "         [ 0.1878, -0.0376, -0.9815],\n",
       "         [ 0.1878,  0.0376, -0.9815],\n",
       "         [ 0.1868,  0.1121, -0.9760],\n",
       "         [ 0.1847,  0.1847, -0.9653],\n",
       "         [ 0.1818,  0.2545, -0.9498]],\n",
       "\n",
       "        [[ 0.2506, -0.2506, -0.9351],\n",
       "         [ 0.2545, -0.1818, -0.9498],\n",
       "         [ 0.2572, -0.1102, -0.9600],\n",
       "         [ 0.2586, -0.0369, -0.9653],\n",
       "         [ 0.2586,  0.0369, -0.9653],\n",
       "         [ 0.2572,  0.1102, -0.9600],\n",
       "         [ 0.2545,  0.1818, -0.9498],\n",
       "         [ 0.2506,  0.2506, -0.9351]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "z=-torch.ones_like(x)/np.tan((2 * math.pi * 30 / 360)/2)\n",
    "\n",
    "def normalize_vecs(vectors: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalize vector lengths.\n",
    "    \"\"\"\n",
    "    return vectors / (torch.norm(vectors, dim=-1, keepdim=True))\n",
    "\n",
    "normalize_vecs(torch.stack([x, y, z], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000, -1.0000, -3.7321],\n",
       "         [-1.0000, -0.7143, -3.7321],\n",
       "         [-1.0000, -0.4286, -3.7321],\n",
       "         [-1.0000, -0.1429, -3.7321],\n",
       "         [-1.0000,  0.1429, -3.7321],\n",
       "         [-1.0000,  0.4286, -3.7321],\n",
       "         [-1.0000,  0.7143, -3.7321],\n",
       "         [-1.0000,  1.0000, -3.7321]],\n",
       "\n",
       "        [[-0.7143, -1.0000, -3.7321],\n",
       "         [-0.7143, -0.7143, -3.7321],\n",
       "         [-0.7143, -0.4286, -3.7321],\n",
       "         [-0.7143, -0.1429, -3.7321],\n",
       "         [-0.7143,  0.1429, -3.7321],\n",
       "         [-0.7143,  0.4286, -3.7321],\n",
       "         [-0.7143,  0.7143, -3.7321],\n",
       "         [-0.7143,  1.0000, -3.7321]],\n",
       "\n",
       "        [[-0.4286, -1.0000, -3.7321],\n",
       "         [-0.4286, -0.7143, -3.7321],\n",
       "         [-0.4286, -0.4286, -3.7321],\n",
       "         [-0.4286, -0.1429, -3.7321],\n",
       "         [-0.4286,  0.1429, -3.7321],\n",
       "         [-0.4286,  0.4286, -3.7321],\n",
       "         [-0.4286,  0.7143, -3.7321],\n",
       "         [-0.4286,  1.0000, -3.7321]],\n",
       "\n",
       "        [[-0.1429, -1.0000, -3.7321],\n",
       "         [-0.1429, -0.7143, -3.7321],\n",
       "         [-0.1429, -0.4286, -3.7321],\n",
       "         [-0.1429, -0.1429, -3.7321],\n",
       "         [-0.1429,  0.1429, -3.7321],\n",
       "         [-0.1429,  0.4286, -3.7321],\n",
       "         [-0.1429,  0.7143, -3.7321],\n",
       "         [-0.1429,  1.0000, -3.7321]],\n",
       "\n",
       "        [[ 0.1429, -1.0000, -3.7321],\n",
       "         [ 0.1429, -0.7143, -3.7321],\n",
       "         [ 0.1429, -0.4286, -3.7321],\n",
       "         [ 0.1429, -0.1429, -3.7321],\n",
       "         [ 0.1429,  0.1429, -3.7321],\n",
       "         [ 0.1429,  0.4286, -3.7321],\n",
       "         [ 0.1429,  0.7143, -3.7321],\n",
       "         [ 0.1429,  1.0000, -3.7321]],\n",
       "\n",
       "        [[ 0.4286, -1.0000, -3.7321],\n",
       "         [ 0.4286, -0.7143, -3.7321],\n",
       "         [ 0.4286, -0.4286, -3.7321],\n",
       "         [ 0.4286, -0.1429, -3.7321],\n",
       "         [ 0.4286,  0.1429, -3.7321],\n",
       "         [ 0.4286,  0.4286, -3.7321],\n",
       "         [ 0.4286,  0.7143, -3.7321],\n",
       "         [ 0.4286,  1.0000, -3.7321]],\n",
       "\n",
       "        [[ 0.7143, -1.0000, -3.7321],\n",
       "         [ 0.7143, -0.7143, -3.7321],\n",
       "         [ 0.7143, -0.4286, -3.7321],\n",
       "         [ 0.7143, -0.1429, -3.7321],\n",
       "         [ 0.7143,  0.1429, -3.7321],\n",
       "         [ 0.7143,  0.4286, -3.7321],\n",
       "         [ 0.7143,  0.7143, -3.7321],\n",
       "         [ 0.7143,  1.0000, -3.7321]],\n",
       "\n",
       "        [[ 1.0000, -1.0000, -3.7321],\n",
       "         [ 1.0000, -0.7143, -3.7321],\n",
       "         [ 1.0000, -0.4286, -3.7321],\n",
       "         [ 1.0000, -0.1429, -3.7321],\n",
       "         [ 1.0000,  0.1429, -3.7321],\n",
       "         [ 1.0000,  0.4286, -3.7321],\n",
       "         [ 1.0000,  0.7143, -3.7321],\n",
       "         [ 1.0000,  1.0000, -3.7321]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x,y,z],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_rays_trig(n, num_steps, fov, resolution, ray_start, ray_end):\n",
    "    \"\"\"Returns sample points, z_vals, and ray directions in camera space.\"\"\"\n",
    "\n",
    "    W, H = resolution\n",
    "    # Create full screen NDC (-1 to +1) coords [x, y, 0, 1].\n",
    "    # Y is flipped to follow image memory layouts.\n",
    "    x, y = torch.meshgrid(torch.linspace(-1, 1, W),\n",
    "                          torch.linspace(1, -1, H, )) # x,y grid , it descrete -1 to 1 with W resolution\n",
    "    x = x.T.flatten() # transform하면 적절하게 x좌표에 맞는다.\n",
    "    y = y.T.flatten() #  transform하면 잘 맞는다.\n",
    "    z = -torch.ones_like(x) / np.tan((2 * math.pi * fov / 360)/2) # \n",
    "\n",
    "    rays_d_cam = normalize_vecs(torch.stack([x, y, z], -1))\n",
    "\n",
    "\n",
    "    z_vals = torch.linspace(ray_start, ray_end, num_steps).reshape(1, num_steps, 1).repeat(W*H, 1, 1)\n",
    "    points = rays_d_cam.unsqueeze(1).repeat(1, num_steps, 1) * z_vals\n",
    "\n",
    "    points = torch.stack(n*[points])\n",
    "    z_vals = torch.stack(n*[z_vals])\n",
    "    rays_d_cam = torch.stack(n*[rays_d_cam])\n",
    "\n",
    "    return points, z_vals, rays_d_cam\n",
    "\n",
    "points,z_vals,rays_d_cam=get_initial_rays_trig(1,1,30,(8,8),2,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 1, 3]), torch.Size([1, 64, 1, 1]), torch.Size([1, 64, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape,z_vals.shape,rays_d_cam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jaepoong')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f88c50d959b1748929a19d038c3f73c8cba63c7f66d12bcb1b51825bde3aa7df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
